# Enable secondary expansion at the very top for proper variable handling
.SECONDEXPANSION:

# Input variables
INPUT_FILE ?=
OUTPUT_DIR ?=
SPECIES_ID ?=
REQUIRE_UTRS ?= yes
LAUNCHER ?= python
PRED_BATCH_SIZE ?= 32
PRED_DTYPE ?= bfloat16

# Model configuration
HEAD_MODEL_PATH ?= plantcad/GeneCAD-l8-d768-PC2-Large
BASE_MODEL_PATH ?= kuleshov-group/PlantCAD2-Large-l48-d1536

# Validate required variables
ifndef INPUT_FILE
  $(error INPUT_FILE is required. Set it via: INPUT_FILE=/path/to/input.fasta)
endif
ifndef OUTPUT_DIR
  $(error OUTPUT_DIR is required. Set it via: OUTPUT_DIR=/path/to/output)
endif
ifndef SPECIES_ID
  $(error SPECIES_ID is required. Set it via: SPECIES_ID=species_id)
endif

# Pipeline directory structure
PIPELINE_DIR = $(OUTPUT_DIR)/pipeline
CHROMOSOME_LIST = $(PIPELINE_DIR)/chromosomes.txt

# Define all pipeline targets
.PHONY: all clean help sequences predictions annotations extract_chromosomes
all: $(OUTPUT_DIR)/predictions.gff

# Help target
help:
	@echo "Available targets:"
	@echo "  all - Run complete prediction pipeline for all chromosomes"
	@echo "  extract_chromosomes - Extract chromosome headers from FASTA"
	@echo "  sequences - Extract sequences for all chromosomes"
	@echo "  predictions - Generate predictions for all chromosomes"
	@echo "  annotations - Generate final GFF with all chromosomes"
	@echo "  clean - Remove all generated files"
	@echo ""
	@echo "Required variables:"
	@echo "  INPUT_FILE - Path to input FASTA file"
	@echo "  SPECIES_ID - Species identifier"
	@echo "  OUTPUT_DIR - Output directory for results"
	@echo ""
	@echo "Optional variables:"
	@echo "  REQUIRE_UTRS - Require UTRs in final output (default: yes)"
	@echo "  HEAD_MODEL_PATH - Path to GeneCAD model checkpoint"
	@echo "  BASE_MODEL_PATH - Path to PlantCAD model checkpoint (default: kuleshov-group/PlantCAD2-Large-l48-d1536)"
	@echo "  LAUNCHER - Command launcher for GPU jobs (default: python)"
	@echo "  PRED_BATCH_SIZE - Batch size for prediction (default: 32)"

# Extract chromosome headers from FASTA file
$(CHROMOSOME_LIST): $(INPUT_FILE)
	@mkdir -p $(PIPELINE_DIR)
	@echo "Extracting chromosome headers from FASTA file..."
	python scripts/extract_chromosome_headers.py \
	  --input $(INPUT_FILE) \
	  --output $(CHROMOSOME_LIST)
	@echo "Chromosome headers extracted successfully"

# Get chromosome IDs from the chromosome list file (delayed evaluation)
define GET_CHROM_IDS
$(shell cat $(CHROMOSOME_LIST) 2>/dev/null | tr '\n' ' ' | sed 's/ $$//')
endef

# Helper function to check if GFF file has data (non-empty and contains feature records)
define check_gff_has_data_shell
[ -f "$1" ] && [ -s "$1" ] && grep -q "^[^#]" "$1"
endef

# Pattern rule for extracting sequences for each chromosome
$(PIPELINE_DIR)/sequences_%.zarr: $(INPUT_FILE) | $(CHROMOSOME_LIST)
	@mkdir -p $(PIPELINE_DIR)
	@echo "Extracting sequences for chromosome: $*"
	python scripts/extract.py extract_fasta_file \
	  --species-id $(SPECIES_ID) \
	  --fasta-file $(INPUT_FILE) \
	  --chrom-map "$*:$*" \
	  --tokenizer-path $(BASE_MODEL_PATH) \
	  --output $@
	@echo "Sequences extracted for chromosome: $*"

# Pattern rule for generating predictions for each chromosome
$(PIPELINE_DIR)/predictions_%.zarr: $(PIPELINE_DIR)/sequences_%.zarr
	@echo "Generating predictions for chromosome: $*"
	$(LAUNCHER) scripts/predict.py create_predictions \
	  --input $< \
	  --output-dir $@ \
	  --model-path $(BASE_MODEL_PATH) \
	  --model-checkpoint $(HEAD_MODEL_PATH) \
	  --species-id $(SPECIES_ID) \
	  --chromosome-id $* \
	  --batch-size $(PRED_BATCH_SIZE) \
	  --dtype $(PRED_DTYPE)
	@echo "Predictions generated for chromosome: $*"

# Pattern rule for detecting intervals for each chromosome
$(PIPELINE_DIR)/intervals_%.zarr: $(PIPELINE_DIR)/predictions_%.zarr
	@echo "Detecting intervals for chromosome: $*"
	python scripts/predict.py detect_intervals \
	  --input-dir $< \
	  --output $@ \
	  --decoding-methods "direct,viterbi" \
	  --remove-incomplete-features yes
	@echo "Intervals detected for chromosome: $*"

# Pattern rule for exporting raw GFF for each chromosome
$(PIPELINE_DIR)/predictions__raw_%.gff: $(PIPELINE_DIR)/intervals_%.zarr
	@echo "Exporting raw GFF for chromosome: $*"
	python scripts/predict.py export_gff \
	  --input $< \
	  --output $@ \
	  --chromosome-id $* \
	  --decoding-method viterbi \
	  --min-transcript-length 3 \
	  --strip-introns yes
	@echo "Raw GFF exported for chromosome: $*"

# Pattern rule for filtering by feature length for each chromosome - with skip logic
$(PIPELINE_DIR)/predictions__raw__feat_len_2_%.gff: $(PIPELINE_DIR)/predictions__raw_%.gff
	@echo "Checking if $< has data for chromosome $*..."
	if $(call check_gff_has_data_shell,$<); then \
	echo "Processing feature length filtering for chromosome $*"; \
	python scripts/gff.py filter_to_min_feature_length \
		--input $< \
		--output $@ \
		--feature-types "five_prime_UTR,three_prime_UTR,CDS" \
		--min-length 2; \
	else \
	echo "Skipping feature length filtering for chromosome $* - no valid transcripts found"; \
	touch $@; \
	fi

# Pattern rule for filtering by gene length for each chromosome - with skip logic
$(PIPELINE_DIR)/predictions__raw__feat_len_2__gene_len_30_%.gff: $(PIPELINE_DIR)/predictions__raw__feat_len_2_%.gff
	@echo "Checking if $< has data for chromosome $*..."
	@if $(call check_gff_has_data_shell,$<); then \
	echo "Processing gene length filtering for chromosome $*"; \
	python scripts/gff.py filter_to_min_gene_length \
		--input "$<" \
		--output "$@" \
		--min-length 30; \
	else \
	echo "Skipping gene length filtering for chromosome $* - likely no valid transcripts after previous steps"; \
	touch "$@"; \
	fi

# Pattern rule for filtering to valid genes for each chromosome - with skip logic
$(PIPELINE_DIR)/predictions__raw__feat_len_2__gene_len_30__has_req_feats_%.gff: $(PIPELINE_DIR)/predictions__raw__feat_len_2__gene_len_30_%.gff
	@echo "Checking if $< has data for chromosome $*..."
	@if $(call check_gff_has_data_shell,$<); then \
	echo "Processing valid gene filtering for chromosome $*"; \
	python scripts/gff.py filter_to_valid_genes \
		--input "$<" \
		--output "$@" \
		--require-utrs "$(REQUIRE_UTRS)"; \
	else \
	echo "Skipping valid gene filtering for chromosome $* - likely no valid transcripts after previous steps"; \
	touch "$@"; \
	fi

# Target to build all chromosome-specific files
build_all_chromosomes: | $(CHROMOSOME_LIST)
	@echo "Building pipeline for all chromosomes..."
	@chrom_ids=$$(cat $(CHROMOSOME_LIST) 2>/dev/null || echo ""); \
	if [ -z "$$chrom_ids" ]; then \
		echo "Error: No chromosome IDs found in $(CHROMOSOME_LIST)"; \
		exit 1; \
	fi; \
	for chr in $$chrom_ids; do \
		echo "Processing chromosome: $$chr"; \
		$(MAKE) -f $(lastword $(MAKEFILE_LIST)) $(PIPELINE_DIR)/predictions__raw__feat_len_2__gene_len_30__has_req_feats_$${chr}.gff || exit 1; \
	done

# Final target to aggregate all chromosome GFF files
# Update the main target to process all chromosomes - skip empty files
$(OUTPUT_DIR)/predictions.gff: build_all_chromosomes
	@mkdir -p $(OUTPUT_DIR)
	@echo "##gff-version 3" > $@
	@chrom_ids=$$(cat $(CHROMOSOME_LIST) 2>/dev/null); \
	echo "Aggregating GFF files for chromosomes: $$chrom_ids"; \
	for chr in $$chrom_ids; do \
		gff_file="$(PIPELINE_DIR)/predictions__raw__feat_len_2__gene_len_30__has_req_feats_$${chr}.gff"; \
		if [ -f "$$gff_file" ] && [ -s "$$gff_file" ] && grep -q "^[^#]" "$$gff_file"; then \
			echo "Including GFF data for chromosome: $$chr"; \
			echo "##sequence-region $$chr 1 999999999" >> $@; \
			cat "$$gff_file" | grep -v "^#" >> $@; \
		else \
			echo "Warning: Skipping chromosome $$chr - no valid GFF data found"; \
		fi; \
	done
	@if ! grep -q "^[^#]" $@; then \
		echo "Warning: Final GFF file contains no feature records - all chromosomes were skipped"; \
		echo "## No valid transcripts were found in any chromosome" >> $@; \
	fi
	@echo "Final GFF file created at: $@"

# Clean target
clean:
	rm -rf $(OUTPUT_DIR)
